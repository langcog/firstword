---
title: "FW_cogsci"
output: html_document
---

`r library(knitr)`
`r opts_chunk$set(message=FALSE, warning=FALSE)`

Preliminaries.
```{r}
rm(list=ls())
library(ggplot2)
library(plyr)
library(reshape2)
library(dplyr)
library(stringr)
library(tidyr)
library(markdown)
library(directlabels)
library(magrittr)


theme_set(theme_bw())
```

Read data.
```{r}
df_turk=read.csv("../data/FW_TurkData.csv") #Turk data
df_cdm=read.csv("../data/CDMlangsurvey_analysis.csv") #CDM data
df_info=read.csv("../data/FW_childesinfo.csv") #Childesinfo data
wg.categories <- read.csv("../data/wg_categories.csv")
wg.codes <- read.csv("../data/WG_CODES.csv") 
childes.freqs <- read.csv('../data/childes.freqs.csv')
phon.complexity <- read.csv('../data/complexity_childesfreqs.csv')

```

```{r}
df_turk %<>%
  mutate(birth = factor(birth_order),
         age.grp = cut(age,breaks = c(5,10,14,18,24)),
         currage.grp = cut(age_current,breaks = c(-1,seq(2,18,2))),
         agesplit = cut(age,breaks = c(0,12,24)),
         dataset = "MTurk")

df_cdm$agesplit <- cut(df_cdm$age, breaks=c(0,12,24))
df_info$agesplit <- cut(df_info$age, breaks=c(0,12,24))
```

bind together.
```{r}
df_cdm$dataset <- "CDM"
df_info$dataset <- "Info"

d <- rbind.fill(df_turk,df_cdm,df_info) %>%
  rename(Category = cdi_cat)
```

Pull in wordbank demographics
```{r, message=FALSE}
wordbank <- src_mysql(dbname='wordbank',host="54.200.225.86", 
                      user="wordbank",password="wordbank")

## NOW LOAD TABLES ##
admin.table <- tbl(wordbank, "common_administration")
child.table <- tbl(wordbank,"common_child")
wg.table <- tbl(wordbank,"instruments_wg")

# Get the age of each child
admins <- admin.table %>%
  select(data_id,child_id,age,source_id) %>%
  rename(id = data_id, child.id = child_id,source.id = source_id) %>%
  as.data.frame

# Get demographic variables for each child
demos <- select(child.table,id,gender,mom_ed,birth_order) %>%
  rename(child.id = id) %>%
  as.data.frame# Rename id fields

# Join age and demographics together
child.data <- as.tbl(left_join(admins,demos))
```

Pull in wordbank data
```{r}
# Select just the MCDI words from the Words and Sentences Table
wg.vocab.words <- select(wg.table,basetable_ptr_id,
                         col_baabaa:col_some) %>%
  as.data.frame %>%
  rename(id = basetable_ptr_id) %>% # Rename the id
  gather(word,produces,col_baabaa:col_some) %>% # Arrange in longform
  mutate(word = str_replace(word, "col_", "")) %>%
  as.tbl# Strip off col_ from words

wg.vocab.words <- left_join(wg.vocab.words,wg.categories,by=c("word"="Lemma"))
wg.vocab.words <- left_join(wg.vocab.words,child.data)

one.word.kids <- wg.vocab.words%>% 
  group_by(id,age,gender) %>% 
  summarise(v = sum(produces==2)) %>% 
  filter(v == 1) %>%
  select(-v)

wds.produced.bykid <- wg.vocab.words %>% 
  filter(id %in% one.word.kids$id, produces==2) %>%
  select(-id,-produces) %>%
  mutate(agesplit = cut(age,breaks=c(0,12,24)),
         dataset = "Wordbank") 

# pull in English-readable words
wds.produced.bykid <- left_join(wds.produced.bykid,wg.codes,
                                by = c("word"="code")) %>%
  select(-word) %>%
  rename(word = name)

# Compute a productive vocabulary for each child
wg.scores <- wg.vocab.words %>%
  group_by(id) %>% # Group by child
  summarise(productive = sum(produces == 2)) # Compute productive vocabulary

all.first.productions <- c(as.character(
  unique(filter(d,Category != "N/A")$word_standard)),
  as.character(unique(wds.produced.bykid$word)))

all.first.productions <- unique(sapply(all.first.productions,tolower))
write.csv(all.first.productions,'../data/unique.productions.csv',
          row.names = FALSE)

childes.freqs %<>%
  gather(word,frequency) %>%
  group_by(word) %>%
  summarise(frequency = sum(frequency)) %>%
  mutate(word = sapply(word,function(x) gsub("\\."," ",x)))



wds.produced.frequency <- wds.produced.bykid %>%
  group_by(word) %>%
  summarise(prod.frequency = n())

wds.produced.frequency <- left_join(wds.produced.frequency,childes.freqs)
wds.produced.frequency <- left_join(wds.produced.frequency,phon.complexity,
                                    by=c("word" = "Original.Word"))

cor(wds.produced.frequency$prod.frequency,
    log(wds.produced.frequency$frequency),use="complete")

cor.test(wds.produced.frequency$prod.frequency,
    wds.produced.frequency$unsBPAV,use="complete")

lm1 <- lm(prod.frequency ~ unsTPAV + log(frequency),data=wds.produced.frequency)
lm2 <- lm(prod.frequency ~ unsTPAV,data=wds.produced.frequency)

quartz()
ggplot(wds.produced.frequency, aes(x = word,y = prod.frequency)) + 
  geom_bar(stat="identity")
  
```

Combine MDI data and demographics
```{r, message=FALSE}
wg.data <- left_join(wg.scores, child.data) %>%
  filter(age >= 8 & age <= 16) %>% # filter down to just relevant range
  select(-child.id,-source.id) #drop redundant columns
```


Do analysis over all data for CDI-cats.
```{r}
freqs <- bind_rows(select(d,Category,agesplit,word_standard,dataset),
                   select(wds.produced.bykid,Category,agesplit,word,dataset)) %>%
  filter(!is.na(agesplit), Category != "N/A", dataset == "MTurk" | dataset == "CDM" | dataset == "Info" & word_standard != "Mama" & word_standard != "Dada" | dataset == "Wordbank") %>%
  group_by(dataset, agesplit, Category) %>%
  summarise(n = n()) %>%
  group_by(dataset, agesplit, add=FALSE) %>%
  mutate(prop = n / sum(n),
         Category = factor(Category,
                           levels = Category[order(prop,Category,
                                                   decreasing=TRUE)])) %>%
  filter(!is.na(Category=="NA"))
```

Plot.

```{r}
quartz()
ggplot(data = freqs, 
       aes(x=Category, y=prop, fill=dataset, 
           group=dataset)) + 
  facet_grid(dataset ~ agesplit)+
  geom_histogram(stat="identity") +
  ylab("Proportion of Total") + 
  xlab("MB-CDI Category") +
  scale_fill_brewer(palette="Set1") +
  theme(axis.text.x = element_text(angle=90, hjust = 1))
```


Top 5 words by dataset
```{r}

d.age <- d %>%
  mutate(word = word_standard)


freqs <- bind_rows(select(d.age,word,dataset),
                   select(wds.produced.bykid,word,dataset)) %>%
  filter(!is.na(word), word != "Mama", word != "Dada", word != "NA", word != "N/A") %>%
  group_by(dataset, word) %>%
  summarise(n=n()) %>%
  top_n(5) %>%
  arrange(n, word, dataset) %>%
  group_by(dataset)
```

Plot a table of top 5 words by dataset
```{r}
#Tried doing this, did end up doing it correctly...needs to be done
```

Plot!
```{r}
# quartz()
# ggplot(data = freqs, 
#        aes(x=word, y=prop, fill=dataset, 
#            group=dataset)) + 
#   facet_grid(dataset ~ agesplit)+
#   geom_histogram(stat="identity") +
#   ylab("Proportion of Total") + 
#   xlab("Word") +
#   scale_fill_brewer(palette="Set1") +
#   theme(axis.text.x = element_text(angle=90, hjust = 1))
```


Age CDF graphs
--------------

New workflow required for resampling.

First get wordbank CIs.

```{r}
wg.producers <- wg.data %>%
  group_by(age) %>%
  summarise(prop = sum(productive > 0)/n()) %>%
  mutate(dataset = "Wordbank")

n.samps <- 100

sample.producers <- function(df) {
  df %<>%
    sample_n(nrow(df), replace = TRUE) %>% # resampling step
    group_by(age) %>%
    summarise(prop = sum(productive > 0)/n()) 
  return(df$prop)
}

samps <- replicate(1000, sample.producers(wg.data))
wg.producers$ci.low <- apply(samps, 1, function(x) {quantile(x, .025)})
wg.producers$ci.high <- apply(samps, 1, function(x) {quantile(x, .975)})
```

Now do the resampling for the others.

```{r}
ns <- d %>% 
  filter(!is.na(age), age != "NA", word_standard != "N/A") %>%
  mutate(dataset = factor(dataset), 
         age = floor(age)) %>%
  select(age, dataset)

sample.ns <- function(df) {
  df %<>% 
    sample_n(nrow(df), replace=TRUE) %>%
    group_by(dataset, age) %>%
    summarise(n = n()) %>%
    mutate(cum.n = cumsum(n),
         prop = cum.n / sum(n))
  return(df)
}

samps <- bind_rows(replicate(1000, sample.ns(ns), simplify=FALSE))

samps %<>% group_by(dataset, age) %>%
  summarise(ci.low = quantile(prop, .025), 
            ci.high = quantile(prop, .975))

ns %<>% group_by(dataset, age) %>%
    summarise(n = n()) %>%
    mutate(cum.n = cumsum(n),
         prop = cum.n / sum(n))

ns <- left_join(ns, samps)
```

Bind these two.

```{r}
freqs <- bind_rows(ns, wg.producers)
```

Plot.

```{r,fig.width=5,fig.height=5}
# quartz()
ggplot(data = freqs, 
       aes(x = age, y = prop, colour=dataset, group=dataset))+
  geom_line(size=1.5) + 
  ylab("Cumulative Probability of First Word")+
  xlab("Age (months)") + 
  geom_hline(yintercept=.75, lty=3) + 
  geom_ribbon(aes(ymin = ci.low, ymax= ci.high, fill=dataset), col=.,  alpha = .2) + 
  geom_vline(aes(xintercept=age[prop>.75][1]), lty=3) + 
  scale_x_continuous(breaks=seq(0,24,4))+
  scale_color_brewer(name="Dataset",palette="Set1")+
  theme_bw(base_size=14) +
  theme(legend.position=c(.85,.3)) 
```



First - Turk data

```{r}
#quartz()
freqs <- ddply(df_turk, .(cdi_cat, word_standard, agesplit), summarise, 
               count=length(word_standard)) 

#Normalizing within the age split
freqs <- freqs %>%
group_by(agesplit) %>%
mutate(prop = count/sum(count)) 
#sorting so that the graph looks cool
freqs$cdi_cat <- factor(freqs$cdi_cat, 
                                  levels=unique(with(freqs, cdi_cat
                                  [order(freqs$prop, cdi_cat, 
                                  decreasing = TRUE)])))
#plot of the proportion within the age split with CDI_cat as first word, faceted by the age split - note, N/A categories are excluded
qplot(cdi_cat, prop, geom="bar", position="dodge", stat="identity",
           data=subset(freqs, count>1 & word_standard != "N/A" & cdi_cat != "N/A" & agesplit != "NA")) + 
  theme(axis.text.x=element_text(angle=90, hjust=1, vjust=.5))+
  ylab("Proportion of Children with Utterance") + xlab("CDI Categories")+facet_wrap(~agesplit)
```

Second - CDM data 

```{r}
freqs <- ddply(df_cdm, .(cdi_cat, word_standard, agesplit), summarise, 
               count=length(word_standard))
#normalizing
freqs <- freqs %>%
group_by(agesplit) %>%
mutate(prop = count/sum(count)) 
#sorting
freqs$cdi_cat <- factor(freqs$cdi_cat, 
                                  levels=unique(with(freqs, cdi_cat
                                  [order(freqs$prop, cdi_cat, 
                                  decreasing = TRUE)])))

qplot(cdi_cat, prop, geom="bar", position="dodge", stat="identity",
           data=subset(freqs, count>1 & word_standard != "N/A" & cdi_cat != "N/A" & agesplit != "NA")) + 
  theme(axis.text.x=element_text(angle=90, hjust=1, vjust=.5))+
  ylab("Proportion of Children with Utterance") + xlab("CDI Categories")+facet_wrap(~agesplit)
```

Entropy
-------


```{r}
entropy <- function(x) {
   probs <- x / sum(x,na.rm=TRUE)
   h = - sum (probs * log(probs))
   return(h)
}
```

Start over categories. 

```{r}
d.age %>%
  filter(dataset=="MTurk", !is.na(age)) %>%
  mutate(older = age > median(age)) %>%
  group_by(older, add=FALSE) %>%
  sample_n(663, replace=FALSE) %>% ### FIXME: sample the smaller group size
  group_by(older, Category, add=FALSE) %>%
  summarise(n = n()) %>% 
  group_by(older, add=FALSE) %>% 
  summarise(h = entropy(n))

entropies.age <- d.age %>%
  filter(dataset=="MTurk", !is.na(age)) %>%
  mutate(older = age > median(age)) %>%
  group_by(older, add=FALSE) %>%
  select(Category,subject,age,word)

entropy.difference <- function(d,num.times) {
  diffs <- NULL

  grp.size <- min(table(d$older))
  
  for(i in 1:num.times) {
    
    d.frame <- d %>%
      sample_n(grp.size, replace = FALSE) %>%
      group_by(older, word, add = FALSE) %>%
      summarise(n = n()) %>%
      group_by(older, add= FALSE) %>%
      summarise(h = entropy(n))
    
    diff <- filter(d.frame,older == TRUE)$h - filter(d.frame,older == FALSE)$h
    
    diffs[i] <- diff
    }
  
  return(diffs)
}


  
  d.age %>%
 %>%
  sample_n(663, replace=FALSE) %>% ### FIXME: sample the smaller group size
  group_by(older, Category, add=FALSE) %>%
  summarise(n = n()) %>% 
  group_by(older, add=FALSE) %>% 
  summarise(h = entropy(n))


```

Now word entropy:

```{r}
d.age %>%
  filter(dataset=="MTurk", !is.na(age)) %>%
  mutate(older = age > median(age)) %>%
  group_by(older, add=FALSE) %>%
  sample_n(663, replace=FALSE) %>% ### FIXME: sample the smaller group size
  group_by(older, word, add=FALSE) %>%
  summarise(n = n()) %>% 
  group_by(older, add=FALSE) %>% 
  summarise(h = entropy(n))
```
